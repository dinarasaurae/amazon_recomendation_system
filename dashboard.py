import streamlit as st
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from collections import defaultdict
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.neighbors import NearestNeighbors
import community.community_louvain as community_louvain

def styled_heading(text):
    st.markdown(
        f"""
        <div style="background-color:#ff7e5f;
                    border-radius:10px;
                    padding:10px;
                    text-align:center;
                    color:white;
                    font-weight:bold;
                    font-size:18px;">
            {text}
        </div>
        """,
        unsafe_allow_html=True,
    )

def colored_line():
    st.markdown("<hr style='border:none; height:3px; background:#ff7e5f; margin:10px 0;'>", unsafe_allow_html=True)

@st.cache_data
def load_data(file_path):
    df = pd.read_csv(file_path)

    if "Amazon-Products.csv" in file_path:
        df["discount_price"] = df["discount_price"].astype(str).str.split("‚Çπ", expand=True).get(1)
        df["actual_price"] = df["actual_price"].astype(str).str.split("‚Çπ", expand=True).get(1)

        df["discount_price"] = df["discount_price"].str.replace(',', '').astype(float)
        df["actual_price"] = df["actual_price"].str.replace(',', '').astype(float)

        df["main_category"] = df["main_category"].astype(str).str.replace(' ', '')
        df["sub_category"] = df["sub_category"].astype(str).str.replace(' ', '')

        df["discount_price"] = df["discount_price"].fillna(df["discount_price"].median())
        df["actual_price"] = df["actual_price"].fillna(df["actual_price"].median())

        df["ratings"] = pd.to_numeric(df["ratings"], errors="coerce")
        df["ratings"] = df["ratings"].fillna(df["ratings"].mean())

        columns_to_extract_tags_from = ["name", "main_category", "sub_category"]
        df["Tags"] = df[columns_to_extract_tags_from].fillna("").agg(" ".join, axis=1)

    return df

@st.cache_data
def load_graph(file_path, max_nodes=10000, min_degree=5):
    graph = nx.read_edgelist(file_path, create_using=nx.Graph(), nodetype=int)
    nodes = [node for node, degree in graph.degree() if degree >= min_degree]
    return graph.subgraph(nodes[:max_nodes])

def recommend_for_node(graph, node, num_recommendations=5, max_neighbors=10):
    neighbors = sorted(set(graph.neighbors(node)), key=lambda n: graph.degree(n), reverse=True)[:max_neighbors]
    common_neighbors = defaultdict(int)
    for neighbor in neighbors:
        for n_neighbor in graph.neighbors(neighbor):
            if n_neighbor != node and n_neighbor not in neighbors:
                common_neighbors[n_neighbor] += 1
    recommendations = sorted(common_neighbors.items(), key=lambda x: x[1], reverse=True)
    return [node for node, _ in recommendations[:num_recommendations]]

def content_based_recommendations(df, item_name, top_n=10):
    if item_name not in df['name'].values:
        return pd.DataFrame()
    
    if 'Tags' not in df.columns:
        st.warning("–ö–æ–ª–æ–Ω–∫–∞ 'Tags' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
        return pd.DataFrame()
    
    tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    tfidf_matrix_content = tfidf_vectorizer.fit_transform(df['Tags'].fillna(""))

    n_components = 100  
    svd = TruncatedSVD(n_components=n_components)
    reduced_tfidf_matrix = svd.fit_transform(tfidf_matrix_content)
    
    nn = NearestNeighbors(n_neighbors=top_n + 1, metric="cosine")
    nn.fit(reduced_tfidf_matrix)
    
    item_index = df[df['name'] == item_name].index[0]
    distances, indices = nn.kneighbors([reduced_tfidf_matrix[item_index]])

    recommended_item_indices = indices[0][1:] 
    
    return df.iloc[recommended_item_indices][['name', 'main_category', 'sub_category', 'ratings', 'actual_price']]

def analyze_data(df):
    styled_heading("–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
    st.write(f" **–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ:** {df.shape[0]}")
    st.write(f" **–ß–∏—Å–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π:** {df['main_category'].nunique()}")
    st.write(f" **–ß–∏—Å–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π:** {df['sub_category'].nunique()}")

    missing_values = df.isnull().sum()
    if missing_values.sum() > 0:
        styled_heading(" –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
        st.write(missing_values[missing_values > 0])
    else:
        st.success(" –í –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π!")
    
    styled_heading("–û–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
    if "Unnamed: 0" in df.columns:
        df.drop(columns=["Unnamed: 0"], inplace=True) 
    st.dataframe(df.describe())
    
    duplicate_count = df.duplicated().sum()
    styled_heading("–î—É–±–ª–∏–∫–∞—Ç—ã")
    st.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:** {duplicate_count}")

def plot_category_distribution(df):
    styled_heading("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
    main_category_counts = df['main_category'].value_counts()
    plt.figure(figsize=(10, 6))
    sns.barplot(x=main_category_counts.index, y=main_category_counts.values, palette="viridis")
    plt.xticks(rotation=75)
    plt.xlabel("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏")
    plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
    plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
    st.pyplot(plt)

def plot_ratings_distribution(df):
    styled_heading("‚≠ê –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤")
    plt.figure(figsize=(10, 6))
    sns.histplot(df['ratings'], bins=20, kde=True, color='#ff6b6b', alpha=0.7)
    plt.xlabel("–†–µ–π—Ç–∏–Ω–≥")
    plt.ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
    plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
    st.pyplot(plt)

def plot_top_ratings(df):
    styled_heading("–¢–æ–ø-20 —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ—Ü–µ–Ω–æ–∫")
    rating_counts = df['no_of_ratings'].value_counts().nlargest(20)
    plt.figure(figsize=(12, 6))
    sns.barplot(x=rating_counts.index, y=rating_counts.values, palette="magma")
    plt.xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤")
    plt.ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
    plt.title("–¢–æ–ø-20 —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ—Ç–∑—ã–≤–æ–≤")
    st.pyplot(plt)

def plot_top_subcategories(df):
    styled_heading("–¢–æ–ø-20 –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–æ–≤–∞—Ä–æ–≤")
    df['sub_category'] = df['sub_category'].str.replace('&', 'and').str.replace(',', '').str.replace("'", "").str.replace('-', '').str.title()
    subcat_counts = df['sub_category'].value_counts()
    top_20_subcats = subcat_counts.nlargest(20)

    plt.figure(figsize=(12, 8))
    sns.barplot(y=top_20_subcats.index, x=top_20_subcats.values, palette="coolwarm")
    plt.xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
    plt.ylabel("–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
    plt.title("–¢–æ–ø-20 –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫)")
    st.pyplot(plt)

def visualize_subgraph(graph, node, recommended_nodes):
    subgraph = graph.subgraph([node] + list(graph.neighbors(node)) + recommended_nodes)
    plt.figure(figsize=(8, 6))
    nx.draw(subgraph, node_size=50, node_color='lightblue', edge_color='gray', with_labels=True)
    plt.title(f'–ü–æ–¥–≥—Ä–∞—Ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —É–∑–ª–∞ {node}')
    st.pyplot(plt)

df = load_data("Amazon-Products.csv")
graph = load_graph("com-amazon.ungraph.txt")

st.sidebar.title('–ú–µ–Ω—é')
page = st.sidebar.radio('–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É', ['–ì–ª–∞–≤–Ω–∞—è', '–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥—Ä–∞—Ñ–∞', '–ö–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'])

if page == '–ì–ª–∞–≤–Ω–∞—è':
    st.title('–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É Amazon')
    st.write("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –º–µ–Ω—é —Å–ª–µ–≤–∞.")
    st.write("–í—ã–ø–æ–ª–Ω–∏–ª–∏ –•–∏—Å–∞–º–µ—Ç–¥–∏–Ω–æ–≤–∞ –î–∏–Ω–∞—Ä–∞ –∏ –ë–æ—Ä–∏—Å–æ–≤–∞ –≠–ª–∏–Ω–∞, K3341.")

elif page == '–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö':
    st.title('üìä –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö')
    analyze_data(df)
    
    colored_line()
    plot_category_distribution(df)
    plot_ratings_distribution(df)
    plot_top_ratings(df)
    plot_top_subcategories(df)

elif page == '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥—Ä–∞—Ñ–∞':
    st.title('–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ç–æ–≤–∞—Ä–æ–≤ Amazon')
    node = st.number_input('–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä —É–∑–ª–∞', min_value=0, max_value=len(graph.nodes()) - 1, step=1)
    num_recommendations = st.slider('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π', min_value=1, max_value=10, value=5)
    if st.button('–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'):
        if node in graph:
            recommended_nodes = recommend_for_node(graph, node, num_recommendations)
            st.write(f'–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–∑–ª–∞ {node}: {recommended_nodes}')
            visualize_subgraph(graph, node, recommended_nodes)
        else:
            st.warning('–í—ã–±—Ä–∞–Ω–Ω—ã–π —É–∑–µ–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –≥—Ä–∞—Ñ–µ.')

elif page == '–ö–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏':
    st.title('üìñ –ö–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏')
    item_name = st.text_input('–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞')
    top_n = st.slider('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π', min_value=1, max_value=10, value=5)
    if st.button('–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å'):
        recommendations = content_based_recommendations(df, item_name, top_n)
        if not recommendations.empty:
            st.write(recommendations)
        else:
            st.warning('–¢–æ–≤–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.')
